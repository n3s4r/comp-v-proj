# -*- coding: utf-8 -*-
"""VariantA_SK.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v8FOeQk5li2Z79mXp__XcecsBIQoq5sR
"""

# ============================
# CELL 1: Imports & Setup
# ============================
import os
import random
import glob

import numpy as np
import cv2
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

# For progress bars (optional)
!pip install -q tqdm
from tqdm import tqdm

# ---- Reproducibility ----
def set_seeds(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seeds(42)

# ---- Device ----
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# ============================
# CELL 2: Mount Drive & Paths
# ============================
from google.colab import drive
drive.mount("/content/drive")

# TODO: update this path if your folder is different
ROOT_DIR = "/content/drive/MyDrive/Five-Billion-Pixels"

IMG_DIR = os.path.join(ROOT_DIR, "Image__8bit_NirRGB")
MSK_DIR = os.path.join(ROOT_DIR, "Annotation__index")

print("IMG_DIR:", IMG_DIR)
print("MSK_DIR:", MSK_DIR)


# ----------------------------------------------
# LOAD IMAGES (TIFF)
# ----------------------------------------------
img_files = sorted(glob.glob(os.path.join(IMG_DIR, "*.tif")))
if len(img_files) == 0:
    img_files = sorted(glob.glob(os.path.join(IMG_DIR, "*.tiff")))

print("Number of images:", len(img_files))


# ----------------------------------------------
# LOAD MASKS (PNG)
# ----------------------------------------------
msk_files = sorted(glob.glob(os.path.join(MSK_DIR, "*.png")))

# Fallback if jpg or no extension (optional)
if len(msk_files) == 0:
    msk_files = sorted(glob.glob(os.path.join(MSK_DIR, "*.jpg")))
if len(msk_files) == 0:
    msk_files = sorted(glob.glob(os.path.join(MSK_DIR, "*")))

print("Number of masks:", len(msk_files))

# ----------------------------------------------
# Example prints
# ----------------------------------------------
print("Example image:", img_files[0] if img_files else "None")
print("Example mask :", msk_files[0] if msk_files else "None")


# ----------------------------------------------
# Final warning if mismatch
# ----------------------------------------------
if len(img_files) != len(msk_files):
    print("⚠ WARNING: Number of images and masks do NOT match!")
else:
    print("✓ Image-mask counts match.")

print("len(img_files) =", len(img_files))
print("len(msk_files) =", len(msk_files))
print("Sample imgs:", img_files[:5])
print("Sample msks:", msk_files[:5])

# ============================
# CELL 3: Load & Tile
# ============================

TILE_SIZE = 256
MAX_TILES_PER_IMAGE = 300      # cap per image
MAX_TOTAL_TILES     = 4000     # overall cap


def load_pair(img_path, msk_path):
    """
    Load a 4-channel image (NIR + RGB) and a mask.
    Returns:
        img: (H, W, 4) float32, normalized to [0,1], channels = [R,G,B,NIR]
        msk: (H, W) int64
    """
    # Read 4-channel tiff: expects order [NIR, R, G, B]
    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)  # (H,W,4)
    if img is None:
        raise ValueError(f"Failed to read image: {img_path}")
    if img.shape[-1] != 4:
        raise ValueError(f"Expected 4 channels, got {img.shape} in {img_path}")

    nir = img[:, :, 0]
    r   = img[:, :, 1]
    g   = img[:, :, 2]
    b   = img[:, :, 3]

    # Reorder to [R,G,B,NIR] and normalize
    img = np.stack([r, g, b, nir], axis=-1).astype("float32") / 255.0

    # Load mask
    msk = cv2.imread(msk_path, cv2.IMREAD_UNCHANGED)  # (H,W) or (H,W,3)
    if msk is None:
        raise ValueError(f"Failed to read mask: {msk_path}")

    if msk.ndim == 3:
        msk = msk[:, :, 0]  # if colored indexed TIFF, take one channel

    msk = msk.astype("int64")
    return img, msk


def make_tiles(img, msk, tile_size=TILE_SIZE):
    """
    Given full image & mask, cut into non-overlapping tiles of size tile_size x tile_size.
    img: (H,W,4)
    msk: (H,W)
    Returns list of tiles.
    """
    H, W, _ = img.shape
    tiles_img = []
    tiles_msk = []

    for y in range(0, H, tile_size):
        for x in range(0, W, tile_size):
            if y + tile_size <= H and x + tile_size <= W:
                tile_img = img[y:y+tile_size, x:x+tile_size, :]  # (256,256,4)
                tile_msk = msk[y:y+tile_size, x:x+tile_size]     # (256,256)
                tiles_img.append(tile_img)
                tiles_msk.append(tile_msk)

    return tiles_img, tiles_msk


# ---- Generate tiles for the first N images (if you want to limit) ----
NUM_IMAGES_TO_USE = 10   # you can increase later

all_imgs_tiles = []
all_msks_tiles = []

for i in range(min(NUM_IMAGES_TO_USE, len(img_files))):
    print(f"Processing image {i}:")
    img, msk = load_pair(img_files[i], msk_files[i])
    ti, tm = make_tiles(img, msk)

    print(f"  -> originally {len(ti)} tiles")

    # Convert to arrays temporarily to sample
    ti = np.array(ti, dtype="float32")
    tm = np.array(tm, dtype="int64")

    # Limit tiles per image
    if len(ti) > MAX_TILES_PER_IMAGE:
        idx = np.random.choice(len(ti), MAX_TILES_PER_IMAGE, replace=False)
        ti = ti[idx]
        tm = tm[idx]
        print(f"  -> downsampled to {len(ti)} tiles")

    all_imgs_tiles.extend(list(ti))
    all_msks_tiles.extend(list(tm))

    # Overall cap
    if len(all_imgs_tiles) >= MAX_TOTAL_TILES:
        print("Reached MAX_TOTAL_TILES cap.")
        break

all_imgs_tiles = np.array(all_imgs_tiles, dtype="float32")   # (N,256,256,4)
all_msks_tiles = np.array(all_msks_tiles, dtype="int64")     # (N,256,256)

print("Total tiles (images):", all_imgs_tiles.shape)
print("Total tiles (masks) :", all_msks_tiles.shape)

# ============================
# CELL 4: Dataset & DataLoader (updated, no stratify)
# ============================

from sklearn.model_selection import train_test_split

# ---- Train/Val split ----
X_train, X_val, y_train, y_val = train_test_split(
    all_imgs_tiles,
    all_msks_tiles,
    test_size=0.2,
    random_state=42,
    shuffle=True
)

print("Train tiles:", X_train.shape)
print("Val tiles  :", X_val.shape)


class SegmentationDataset(Dataset):
    def __init__(self, images, masks, augment=False):
        """
        images: (N,H,W,4), float32
        masks : (N,H,W), int64
        """
        self.images = images
        self.masks = masks
        self.augment = augment

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = self.images[idx]   # (H,W,4)
        mask  = self.masks[idx]    # (H,W)

        # to torch: (4,H,W)
        image = torch.from_numpy(image).permute(2, 0, 1)   # (4,256,256)
        mask  = torch.from_numpy(mask).long()              # (256,256)

        # ---- Simple augmentations ----
        if self.augment:
            # horizontal flip
            if random.random() < 0.5:
                image = torch.flip(image, dims=[2])  # flip width
                mask  = torch.flip(mask,  dims=[1])

            # vertical flip
            if random.random() < 0.5:
                image = torch.flip(image, dims=[1])
                mask  = torch.flip(mask,  dims=[0])

            # 90° rotation
            if random.random() < 0.5:
                image = image.permute(0, 2, 1)
                mask  = mask.permute(1, 0)

            # brightness/contrast jitter (very simple)
            if random.random() < 0.3:
                factor = 0.9 + 0.2 * random.random()  # [0.9, 1.1]
                image = image * factor
                image = torch.clamp(image, 0.0, 1.0)

        return image, mask


BATCH_SIZE = 4

train_dataset = SegmentationDataset(X_train, y_train, augment=True)
val_dataset   = SegmentationDataset(X_val,   y_val,   augment=False)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)

print("Train batches:", len(train_loader))
print("Val batches  :", len(val_loader))

# ============================
# CELL 5: SKConv & SKBottleneck
# ============================

class SKConv(nn.Module):
    """
    Simplified Selective Kernel convolution.
    M = number of branches (e.g. 2: 3x3 and 5x5).
    """
    def __init__(self, in_channels, out_channels, stride=1, M=2, G=32, r=16, L=32):
        super(SKConv, self).__init__()
        d = max(in_channels // r, L)
        self.M = M
        self.out_channels = out_channels

        # Multi-branch convs (3x3, 5x5)
        self.convs = nn.ModuleList()
        for i in range(M):
            k = 3 + 2 * i     # 3, 5, ...
            padding = k // 2
            self.convs.append(
                nn.Conv2d(
                    in_channels,
                    out_channels,
                    kernel_size=k,
                    stride=stride,
                    padding=padding,
                    groups=G,
                    bias=False
                )
            )

        self.bn = nn.BatchNorm2d(out_channels)

        # Squeeze
        self.fc = nn.Linear(out_channels, d)
        # Excitation branches
        self.fcs = nn.ModuleList()
        for _ in range(M):
            self.fcs.append(nn.Linear(d, out_channels))

        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        batch_size = x.size(0)

        # Step 1: multi-branch convs
        feats = []
        for conv in self.convs:
            feats.append(conv(x))

        # Sum for shortcut aggregation
        U = sum(feats)              # (B, C, H, W)
        U = self.bn(U)

        # Step 2: global pooling
        s = F.adaptive_avg_pool2d(U, 1).view(batch_size, -1)   # (B, C)

        # Step 3: squeeze
        z = self.fc(s)             # (B, d)
        z = F.relu(z, inplace=True)

        # Step 4: excitation for each branch
        attention_vectors = []
        for fc in self.fcs:
            attention_vectors.append(fc(z).unsqueeze(1))  # (B,1,C)

        attention = torch.cat(attention_vectors, dim=1)   # (B, M, C)
        attention = self.softmax(attention)               # softmax across M

        # Step 5: fuse
        attention = attention.unsqueeze(-1).unsqueeze(-1) # (B,M,C,1,1)

        feats_stack = torch.stack(feats, dim=1)           # (B,M,C,H,W)
        V = (attention * feats_stack).sum(dim=1)          # (B,C,H,W)

        return V


class SKBottleneck(nn.Module):
    expansion = 4

    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=32, base_width=4):
        """
        inplanes: input channels
        planes:   base planes (before expansion)
        stride:   stride for the SKConv (for downsampling)
        """
        super(SKBottleneck, self).__init__()
        width = int(planes * (base_width / 64.0)) * groups

        # 1x1 reduce
        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(width)

        # SKConv instead of normal 3x3
        self.conv2 = SKConv(width, width, stride=stride, M=2, G=groups)
        self.bn2 = nn.BatchNorm2d(width)

        # 1x1 expand
        self.conv3 = nn.Conv2d(width, planes * self.expansion, kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm2d(planes * self.expansion)

        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample

    def forward(self, x):
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out

# ============================
# CELL 6: SK-ResNeXt backbone (4-ch)
# ============================

class SKResNeXt(nn.Module):
    """
    SK-ResNeXt-50 style backbone (3,4,6,3 blocks) with 4-channel input support.
    """
    def __init__(self, block, layers, num_classes=1000, in_channels=4, groups=32, width_per_group=4):
        super(SKResNeXt, self).__init__()
        self.inplanes = 64
        self.groups = groups
        self.base_width = width_per_group

        # NOTE: conv1 has in_channels=4 now
        self.conv1 = nn.Conv2d(
            in_channels, 64,
            kernel_size=7, stride=2, padding=3, bias=False
        )
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # Encoder stages
        self.layer1 = self._make_layer(block,  64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)

        # (Classifier head not used for segmentation, but kept for completeness)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)

        # Init
        for m in self.modules():
            if isinstance(m, (nn.Conv2d, nn.Linear)):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')

    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None

        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(
                    self.inplanes,
                    planes * block.expansion,
                    kernel_size=1,
                    stride=stride,
                    bias=False
                ),
                nn.BatchNorm2d(planes * block.expansion),
            )

        layers = []
        layers.append(
            block(
                self.inplanes, planes,
                stride=stride,
                downsample=downsample,
                groups=self.groups,
                base_width=self.base_width
            )
        )
        self.inplanes = planes * block.expansion

        for _ in range(1, blocks):
            layers.append(
                block(
                    self.inplanes, planes,
                    stride=1,
                    downsample=None,
                    groups=self.groups,
                    base_width=self.base_width
                )
            )

        return nn.Sequential(*layers)

    def forward(self, x):
        # We'll actually use the individual layers in the UNet, not fc
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)      # x0
        x0 = x

        x = self.maxpool(x)

        x1 = self.layer1(x)   # 256 ch
        x2 = self.layer2(x1)  # 512 ch
        x3 = self.layer3(x2)  # 1024 ch
        x4 = self.layer4(x3)  # 2048 ch

        return x0, x1, x2, x3, x4


def sk_resnext50_4ch():
    """
    Helper function to construct SK-ResNeXt-50-like backbone with 4-channel input.
    """
    model = SKResNeXt(
        block=SKBottleneck,
        layers=[3, 4, 6, 3],  # ResNet-50 / ResNeXt-50 config
        in_channels=4,
        groups=32,
        width_per_group=4
    )
    return model

# ============================
# CELL 7: ConvBlock, AttentionGate, Variant A UNet
# ============================

class ConvBlock(nn.Module):
    def __init__(self, in_c, out_c):
        super().__init__()
        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False)
        self.bn1   = nn.BatchNorm2d(out_c)
        self.relu  = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False)
        self.bn2   = nn.BatchNorm2d(out_c)

    def forward(self, x):
        x = self.conv1(x); x = self.bn1(x); x = self.relu(x)
        x = self.conv2(x); x = self.bn2(x); x = self.relu(x)
        return x


class AttentionGate(nn.Module):
    def __init__(self, in_x, in_g, inter_channels):
        """
        in_x: channels of the skip connection
        in_g: channels of the gating (decoder) feature
        """
        super().__init__()
        self.theta   = nn.Conv2d(in_x, inter_channels, kernel_size=1, bias=False)
        self.phi     = nn.Conv2d(in_g, inter_channels, kernel_size=1, bias=False)
        self.psi     = nn.Conv2d(inter_channels, 1, kernel_size=1, bias=True)
        self.relu    = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x, g):
        # x: skip from encoder
        # g: gating from decoder
        theta_x = self.theta(x)
        phi_g   = self.phi(g)

        f = self.relu(theta_x + phi_g)
        psi = self.sigmoid(self.psi(f))    # (B,1,H,W)

        return x * psi                      # elementwise attention


class VariantA_SKResNeXt_UNet(nn.Module):
    def __init__(self, n_classes=25):
        super().__init__()

        # ---- Encoder: 4-channel SK-ResNeXt-50 ----
        self.backbone = sk_resnext50_4ch()

        # We break out the enc0 step (conv1+bn+relu) and pool
        self.enc0_conv = self.backbone.conv1
        self.enc0_bn   = self.backbone.bn1
        self.enc0_relu = self.backbone.relu
        self.pool0     = self.backbone.maxpool

        self.enc1 = self.backbone.layer1   # 256 ch
        self.enc2 = self.backbone.layer2   # 512 ch
        self.enc3 = self.backbone.layer3   # 1024 ch
        self.enc4 = self.backbone.layer4   # 2048 ch

        # ---- Decoder (Attention U-Net) ----

        # 1st up: 2048 -> combine with 1024 (x3)
        self.up1  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        self.att1 = AttentionGate(in_x=1024, in_g=2048, inter_channels=256)
        self.d1   = ConvBlock(2048 + 1024, 256)

        # 2nd up: 256 -> combine with 512 (x2)
        self.up2  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        self.att2 = AttentionGate(in_x=512, in_g=256, inter_channels=128)
        self.d2   = ConvBlock(256 + 512, 128)

        # 3rd up: 128 -> combine with 256 (x1)
        self.up3  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        self.att3 = AttentionGate(in_x=256, in_g=128, inter_channels=64)
        self.d3   = ConvBlock(128 + 256, 64)

        # 4th up: 64 -> combine with 64 (x0)
        self.up4  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        self.att4 = AttentionGate(in_x=64, in_g=64, inter_channels=32)
        self.d4   = ConvBlock(64 + 64, 32)

        # Final up back to full resolution
        self.up5  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        self.d5   = ConvBlock(32, 32)

        self.out_conv = nn.Conv2d(32, n_classes, kernel_size=1)

    def forward(self, x):
        """
        x: (B, 4, H, W)  e.g. (B,4,256,256)
        """

        # ---- Encoder ----
        x0 = self.enc0_conv(x)       # (B,64,H/2,W/2)
        x0 = self.enc0_bn(x0)
        x0 = self.enc0_relu(x0)      # first skip

        p0 = self.pool0(x0)          # (B,64,H/4,W/4)

        x1 = self.enc1(p0)           # (B,256,H/4,W/4)
        x2 = self.enc2(x1)           # (B,512,H/8,W/8)
        x3 = self.enc3(x2)           # (B,1024,H/16,W/16)
        x4 = self.enc4(x3)           # (B,2048,H/32,W/32) bottleneck

        # ---- Decoder ----
        u1 = self.up1(x4)            # (B,2048,H/16,W/16)
        a1 = self.att1(x3, u1)
        d1 = self.d1(torch.cat([u1, a1], dim=1))  # (B,256,H/16,W/16)

        u2 = self.up2(d1)            # (B,256,H/8,W/8)
        a2 = self.att2(x2, u2)
        d2 = self.d2(torch.cat([u2, a2], dim=1))  # (B,128,H/8,W/8)

        u3 = self.up3(d2)            # (B,128,H/4,W/4)
        a3 = self.att3(x1, u3)
        d3 = self.d3(torch.cat([u3, a3], dim=1))  # (B,64,H/4,W/4)

        u4 = self.up4(d3)            # (B,64,H/2,W/2)
        a4 = self.att4(x0, u4)
        d4 = self.d4(torch.cat([u4, a4], dim=1))  # (B,32,H/2,W/2)

        u5 = self.up5(d4)            # (B,32,H,W)
        d5 = self.d5(u5)             # (B,32,H,W)

        out = self.out_conv(d5)      # (B,n_classes,H,W)

        return out


# Instantiate model
N_CLASSES = 25  # change if your dataset uses different number of classes

model = VariantA_SKResNeXt_UNet(n_classes=N_CLASSES).to(device)
print("Model initialized. Total parameters:",
      sum(p.numel() for p in model.parameters()) / 1e6, "M")

# ============================
# CELL 8 (REPLACE): Loss, Optimizer, Train/Val (mIoU + Acc + Time)
# ============================
import time
import torch
import torch.nn as nn
from tqdm import tqdm

# ---- Loss ----
criterion = nn.CrossEntropyLoss()   # multi-class pixel-wise

# ---- Optimizer ----
LEARNING_RATE = 1e-4
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

@torch.no_grad()
def compute_iou_from_logits(logits, target, num_classes):
    """
    logits: (B,C,H,W)
    target: (B,H,W)
    """
    pred = torch.argmax(logits, dim=1)  # (B,H,W)

    pred = pred.view(-1)
    target = target.view(-1)

    ious = []
    for cls in range(num_classes):
        pred_inds = (pred == cls)
        target_inds = (target == cls)
        inter = (pred_inds & target_inds).sum().item()
        union = (pred_inds | target_inds).sum().item()
        if union == 0:
            continue
        ious.append(inter / union)

    return 0.0 if len(ious) == 0 else sum(ious) / len(ious)

@torch.no_grad()
def pixel_accuracy_from_logits(logits, target):
    """
    logits: (B,C,H,W)
    target: (B,H,W)
    """
    pred = torch.argmax(logits, dim=1)
    correct = (pred == target).sum().item()
    total = target.numel()
    return correct / max(total, 1)

def train_one_epoch(model, loader, optimizer, criterion, device, num_classes):
    model.train()
    t0 = time.time()

    total_loss = 0.0
    total_iou  = 0.0
    total_acc  = 0.0
    n_batches  = 0

    for imgs, msks in tqdm(loader, desc="Train", leave=False):
        imgs = imgs.to(device, non_blocking=True)
        msks = msks.to(device, non_blocking=True).long()

        optimizer.zero_grad(set_to_none=True)

        logits = model(imgs)
        loss = criterion(logits, msks)

        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        total_iou  += compute_iou_from_logits(logits, msks, num_classes)
        total_acc  += pixel_accuracy_from_logits(logits, msks)
        n_batches  += 1

    epoch_time = time.time() - t0
    return (total_loss / n_batches,
            total_iou  / n_batches,
            total_acc  / n_batches,
            epoch_time)

@torch.no_grad()
def validate_one_epoch(model, loader, criterion, device, num_classes):
    model.eval()
    t0 = time.time()

    total_loss = 0.0
    total_iou  = 0.0
    total_acc  = 0.0
    n_batches  = 0

    for imgs, msks in tqdm(loader, desc="Val", leave=False):
        imgs = imgs.to(device, non_blocking=True)
        msks = msks.to(device, non_blocking=True).long()

        logits = model(imgs)
        loss = criterion(logits, msks)

        total_loss += loss.item()
        total_iou  += compute_iou_from_logits(logits, msks, num_classes)
        total_acc  += pixel_accuracy_from_logits(logits, msks)
        n_batches  += 1

    epoch_time = time.time() - t0
    return (total_loss / n_batches,
            total_iou  / n_batches,
            total_acc  / n_batches,
            epoch_time)

# ============================
# CELL 9 (REPLACE): Train Loop (Variant B-style metrics + history + best save)
# ============================
import os
import pandas as pd
import torch

NUM_EPOCHS = 40

best_val_miou = -1.0
save_path = "/content/drive/MyDrive/cse468_variantA_SKResNeXt_UNet_best.pth"
history_csv = "/content/drive/MyDrive/VariantA_history.csv"

history = {
    "epoch": [],
    "train_loss": [], "train_miou": [], "train_acc": [], "train_time_sec": [],
    "val_loss":   [], "val_miou":   [], "val_acc":   [], "val_time_sec":   []
}

for epoch in range(1, NUM_EPOCHS + 1):
    print(f"\nEpoch {epoch}/{NUM_EPOCHS}")

    train_loss, train_miou, train_acc, train_time = train_one_epoch(
        model, train_loader, optimizer, criterion, device, N_CLASSES
    )
    val_loss, val_miou, val_acc, val_time = validate_one_epoch(
        model, val_loader, criterion, device, N_CLASSES
    )

    # store history (so plots look like Variant B's)
    history["epoch"].append(epoch)

    history["train_loss"].append(train_loss)
    history["train_miou"].append(train_miou)
    history["train_acc"].append(train_acc)
    history["train_time_sec"].append(train_time)

    history["val_loss"].append(val_loss)
    history["val_miou"].append(val_miou)
    history["val_acc"].append(val_acc)
    history["val_time_sec"].append(val_time)

    # print like Variant B
    print(f"  Train Loss: {train_loss:.4f} | Train mIoU: {train_miou:.4f} | Train Acc: {train_acc:.4f} | Time: {train_time:.1f}s")
    print(f"  Val   Loss: {val_loss:.4f} | Val   mIoU: {val_miou:.4f} | Val   Acc: {val_acc:.4f} | Time: {val_time:.1f}s")

    # save best by val mIoU (same as your old logic, just extended)
    if val_miou > best_val_miou:
        best_val_miou = val_miou
        torch.save({
            "epoch": epoch,
            "model_state": model.state_dict(),
            "optimizer_state": optimizer.state_dict(),
            "best_val_miou": best_val_miou,
            "history": history
        }, save_path)
        print(f"  -> New best model saved with mIoU {best_val_miou:.4f}")

# save history CSV for plotting in next cell
pd.DataFrame(history).to_csv(history_csv, index=False)
print("\n============================")
print(f"Training finished. Best Val mIoU: {best_val_miou:.4f}")
print(f"Best checkpoint: {save_path}")
print(f"History CSV saved: {history_csv}")
print("============================")

# ============================
# CELL 10: Visualization
# ============================

model.eval()
imgs, msks = next(iter(val_loader))
imgs = imgs.to(device)
msks = msks.to(device)

with torch.no_grad():
    logits = model(imgs)
    preds = torch.argmax(logits, dim=1)

imgs = imgs.cpu()
msks = msks.cpu()
preds = preds.cpu()

# Show first sample: RGB only (ignore NIR in visualization)
idx = 0
img_np = imgs[idx].permute(1,2,0).numpy()  # (H,W,4)
rgb_img = img_np[:, :, 1:4]                 # show R,G,B

fig, axs = plt.subplots(1, 3, figsize=(15,5))
axs[0].imshow(rgb_img)
axs[0].set_title("Input RGB")
axs[0].axis("off")

axs[1].imshow(msks[idx], cmap="tab20")
axs[1].set_title("Ground Truth")
axs[1].axis("off")

axs[2].imshow(preds[idx], cmap="tab20")
axs[2].set_title("Prediction")
axs[2].axis("off")

plt.show()

# ============================
# CELL 11 (UPDATED): Plotting Curves (Variant A) - Variant B style
# ============================
import os
import pandas as pd
import matplotlib.pyplot as plt

# --- read history from Drive (because that's where you saved it) ---
variantA_csv = "/content/drive/MyDrive/VariantA_history.csv"
assert os.path.exists(variantA_csv), f"VariantA_history.csv not found at: {variantA_csv}"

histA = pd.read_csv(variantA_csv)
epochs = histA["epoch"].values
print("Loaded Variant A history:", variantA_csv)

# --- save plots to Drive too (so nothing gets lost in Colab temp) ---
SAVE_DIR = "/content/drive/MyDrive/VariantA_Plots"
os.makedirs(SAVE_DIR, exist_ok=True)

def plot_one(x, y, title, ylabel, save_name=None):
    plt.figure()
    plt.plot(x, y)
    plt.xlabel("Epoch")
    plt.ylabel(ylabel)
    plt.title(title)
    plt.grid(True)

    if save_name:
        out_path = os.path.join(SAVE_DIR, save_name)
        plt.savefig(out_path, dpi=200, bbox_inches="tight")
        print("Saved:", out_path)

    plt.show()

# ---- Loss ----
plot_one(epochs, histA["train_loss"].values, "Variant A: Train Loss", "Loss", "VariantA_TrainLoss.png")
plot_one(epochs, histA["val_loss"].values,   "Variant A: Val Loss",   "Loss", "VariantA_ValLoss.png")

# ---- mIoU ----
plot_one(epochs, histA["train_miou"].values, "Variant A: Train mIoU", "mIoU", "VariantA_TrainmIoU.png")
plot_one(epochs, histA["val_miou"].values,   "Variant A: Val mIoU",   "mIoU", "VariantA_ValmIoU.png")

# ---- Overall Accuracy ----
plot_one(epochs, histA["train_acc"].values,  "Variant A: Train Overall Accuracy", "Accuracy", "VariantA_TrainAcc.png")
plot_one(epochs, histA["val_acc"].values,    "Variant A: Val Overall Accuracy",   "Accuracy", "VariantA_ValAcc.png")

# ---- Time per Epoch ----
plot_one(epochs, histA["train_time_sec"].values, "Variant A: Train Time per Epoch", "Seconds", "VariantA_TrainTime.png")
plot_one(epochs, histA["val_time_sec"].values,   "Variant A: Val Time per Epoch",   "Seconds", "VariantA_ValTime.png")

# ---- Best epoch summary ----
best_idx = histA["val_miou"].values.argmax()
best_epoch = int(histA["epoch"].iloc[best_idx])
best_val_miou = float(histA["val_miou"].iloc[best_idx])
best_val_acc  = float(histA["val_acc"].iloc[best_idx])

print("\n===== Variant A Summary =====")
print(f"Best Epoch (by Val mIoU): {best_epoch}")
print(f"Best Val mIoU: {best_val_miou:.4f}")
print(f"Best Val Acc : {best_val_acc:.4f}")
print("=============================\n")